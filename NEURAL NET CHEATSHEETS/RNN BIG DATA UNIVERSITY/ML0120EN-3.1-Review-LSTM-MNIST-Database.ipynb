{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Big Data University](https://ibm.box.com/shared/static/jvcqp2iy2jlx2b32rmzdt0tx8lvxgzkp.png)\n",
    "# <center> Sequence classification with LSTM on MNIST</center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font size = 3><strong>In this notebook you will learn the How to use TensorFlow for create a Recurrent Neural Network</strong></font>\n",
    "<br>    \n",
    "- <a href=\"#intro\">Introduction</a>\n",
    "<br>\n",
    "- <p><a href=\"#arch\">Architectures</a></p>\n",
    "    - <a href=\"#lstm\">Long Short-Term Memory Model (LSTM)</a>\n",
    "\n",
    "- <p><a href=\"#build\">Building a LSTM with TensorFlow</a></p>\n",
    "</div>\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"intro\"/> Introduction\n",
    "Recurrent Neural Networks are Deep Learning models with simple structures and a feedback mechanism builted-in, or in different words, the output of a layer is added to the next input and fed back to the same layer.\n",
    "\n",
    "The Recurrent Neural Network is a specialized type of Neural Network that solves the issue of **maintaining context for Sequential data** -- such as Weather data, Stocks, Genes, etc. At each iterative step, the processing unit takes in an input and the current state of the network, and produces an output and a new state that is **re-fed into the network**.\n",
    "\n",
    "However, **this model has some problems**. It's very computationally expensive to maintain the state for a large amount of units, even more so over a long amount of time. Additionally, Recurrent Networks are very sensitive to changes in their parameters. As such, they are prone to different problems with their Gradient Descent optimizer -- they either grow exponentially (Exploding Gradient) or drop down to near zero and stabilize (Vanishing Gradient), both problems that greatly harm a model's learning capability.\n",
    "\n",
    "To solve these problems, Hochreiter and Schmidhuber published a paper in 1997 describing a way to keep information over long periods of time and additionally solve the oversensitivity to parameter changes, i.e., make backpropagating through the Recurrent Networks more viable.\n",
    "\n",
    "(In this notebook, we will cover only LSTM and its implementation using TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"arch\"/>Architectures\n",
    "- Fully Recurrent Network\n",
    "- Recursive Neural Networks\n",
    "- Hopfield Networks\n",
    "- Elman Networks and Jordan Networks\n",
    "- Echo State Networks\n",
    "- Neural history compressor\n",
    "- **The Long Short-Term Memory Model (LSTM)**\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/v7p90neiaqghmpwawpiecmz9n7080m59.png\" alt=\"Representation of a Recurrent Neural Network\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a id=\"lstm\"/>LSTM\n",
    "LSTM is one of the proposed solutions or upgrades to the **Recurrent Neural Network model**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an abstraction of how computer memory works. It is \"bundled\" with whatever processing unit is implemented in the Recurrent Network, although outside of its flow, and is responsible for keeping, reading, and outputting information for the model. The way it works is simple: you have a linear unit, which is the information cell itself, surrounded by three logistic gates responsible for maintaining the data. One gate is for inputting data into the information cell, one is for outputting data from the input cell, and the last one is to keep or forget data depending on the needs of the network.\n",
    "\n",
    "Thanks to that, it not only solves the problem of keeping states, because the network can choose to forget data whenever information is not needed, it also solves the gradient problems, since the Logistic Gates have a very nice derivative.\n",
    "\n",
    "### Long Short-Term Memory Architecture\n",
    "\n",
    "As seen before, the Long Short-Term Memory is composed of a linear unit surrounded by three logistic gates. The name for these gates vary from place to place, but the most usual names for them are:\n",
    "- the \"Input\" or \"Write\" Gate, which handles the writing of data into the information cell, \n",
    "- the \"Output\" or \"Read\" Gate, which handles the sending of data back onto the Recurrent Network, and \n",
    "- the \"Keep\" or \"Forget\" Gate, which handles the maintaining and modification of the data stored in the information cell.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagram of the Long Short-Term Memory Unit*</center>\n",
    "\n",
    "The three gates are the centerpiece of the LSTM unit. The gates, when activated by the network, perform their respective functions. For example, the Input Gate will write whatever data it is passed onto the information cell, the Output Gate will return whatever data is in the information cell, and the Keep Gate will maintain the data in the information cell. These gates are analog and multiplicative, and as such, can modify the data based on the signal they are sent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"build\"/> Building a LSTM with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM for Classification\n",
    "Although RNN is mostly used to model sequences and predict sequential data, we can still classify images using a LSTM network. If we consider every image row as a sequence of pixels, we can feed a LSTM network for classification. Lets use the famous MNIST dataset here. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Dataset\n",
    "\n",
    "Tensor flow already provides **helper functions** to download and process the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **`input_data.read_data_sets(...)`** loads the entire dataset and returns an object **`tensorflow.contrib.learn.python.learn.datasets.mnist.DataSets`**\n",
    "\n",
    "\n",
    "The argument **(`one_hot=False`)** creates the label arrays as 10-dimensional binary vectors (only zeros and ones), in which the index cell for the number one, is the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:  (55000, 784)\n",
      "Train Labels   (55000, 10)\n",
      "\n",
      "Test Images:   (10000, 784)\n",
      "Test Labels:   (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "trainimgs = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs = mnist.test.images\n",
    "testlabels = mnist.test.labels \n",
    "\n",
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "print \"Train Images: \", trainimgs.shape\n",
    "print \"Train Labels  \", trainlabels.shape\n",
    "print\n",
    "print \"Test Images:  \" , testimgs.shape\n",
    "print \"Test Labels:  \", testlabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get one sample, just to understand the structure of MNIST dataset \n",
    "\n",
    "The next code snippet prints the **label vector** (one_hot format), **the class** and actual sample formatted as **image**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADuCAYAAAAp6fzCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115522990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 100 - Class: [6] - Label Vector: [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.] \n",
      "Sample: 101 - Class: [0] - Label Vector: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] \n",
      "Sample: 102 - Class: [5] - Label Vector: [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.] \n"
     ]
    }
   ],
   "source": [
    "samplesIdx = [100, 101, 102]  #<-- You can change these numbers here to see other samples\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(testimgs[samplesIdx[0]].reshape([28,28]), cmap='gray')\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0,28,28), np.linspace(0,28,28))\n",
    "X =  xx ; Y =  yy\n",
    "Z =  100*np.ones(X.shape)\n",
    "\n",
    "img = testimgs[77].reshape([28,28])\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.set_zlim((0,200))\n",
    "\n",
    "\n",
    "offset=200\n",
    "for i in samplesIdx:\n",
    "    img = testimgs[i].reshape([28,28]).transpose()\n",
    "    ax.contourf(X, Y, img, 200, zdir='z', offset=offset, cmap=\"gray\")\n",
    "    offset -= 100\n",
    "\n",
    "    ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in samplesIdx:\n",
    "    print \"Sample: {0} - Class: {1} - Label Vector: {2} \".format(i, np.nonzero(testlabels[i])[0], testlabels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's Understand the parameters, inputs and outputs\n",
    "\n",
    "We will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. \n",
    "\n",
    "#### Our simple RNN consists of  \n",
    "1. One input layer which converts a $28*28$ dimensional input to an $128$ dimensional hidden layer, \n",
    "2. One intermediate recurrent neural network (LSTM) \n",
    "3. One output layer which converts an $128$ dimensional output of the LSTM to $10$ dimensional output indicating a class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input should be a Tensor of shape: [batch_size, time_steps, input_dimension], but in our case it would be (?, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=\"float\", shape=[None, n_steps, n_input], name=\"x\") # Current data input shape: (batch_size, n_steps, n_input) [100x28x28]\n",
    "y = tf.placeholder(dtype=\"float\", shape=[None, n_classes], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the weight and biases for the read out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a lstm cell with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dynamic_rnn__ creates a recurrent neural network specified from __lstm_cell__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, inputs=x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the rnn would be a [100x28x128] matrix. we use the linear activation to map it to a [?x10 matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tf.reshape(tf.split(outputs, 28, axis=1, num=None, name='split')[-1],[-1,128])\n",
    "pred = tf.matmul(output, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__labels__ and __logits__ should be tensors of shape [100x10], lets check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred ))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the accuracy and evaluation methods to be used in the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just recall that we will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Minibatch Loss= 1.862552, Training Accuracy= 0.31000\n",
      "Iter 2000, Minibatch Loss= 1.650728, Training Accuracy= 0.41000\n",
      "Iter 3000, Minibatch Loss= 1.153341, Training Accuracy= 0.66000\n",
      "Iter 4000, Minibatch Loss= 1.077106, Training Accuracy= 0.65000\n",
      "Iter 5000, Minibatch Loss= 1.035731, Training Accuracy= 0.66000\n",
      "Iter 6000, Minibatch Loss= 0.926979, Training Accuracy= 0.71000\n",
      "Iter 7000, Minibatch Loss= 0.560958, Training Accuracy= 0.81000\n",
      "Iter 8000, Minibatch Loss= 0.841170, Training Accuracy= 0.73000\n",
      "Iter 9000, Minibatch Loss= 0.700860, Training Accuracy= 0.78000\n",
      "Iter 10000, Minibatch Loss= 0.613573, Training Accuracy= 0.82000\n",
      "Iter 11000, Minibatch Loss= 0.394312, Training Accuracy= 0.89000\n",
      "Iter 12000, Minibatch Loss= 0.269624, Training Accuracy= 0.93000\n",
      "Iter 13000, Minibatch Loss= 0.236361, Training Accuracy= 0.92000\n",
      "Iter 14000, Minibatch Loss= 0.353219, Training Accuracy= 0.89000\n",
      "Iter 15000, Minibatch Loss= 0.328590, Training Accuracy= 0.88000\n",
      "Iter 16000, Minibatch Loss= 0.373554, Training Accuracy= 0.87000\n",
      "Iter 17000, Minibatch Loss= 0.354069, Training Accuracy= 0.86000\n",
      "Iter 18000, Minibatch Loss= 0.213457, Training Accuracy= 0.92000\n",
      "Iter 19000, Minibatch Loss= 0.346702, Training Accuracy= 0.89000\n",
      "Iter 20000, Minibatch Loss= 0.195962, Training Accuracy= 0.90000\n",
      "Iter 21000, Minibatch Loss= 0.411174, Training Accuracy= 0.84000\n",
      "Iter 22000, Minibatch Loss= 0.264264, Training Accuracy= 0.90000\n",
      "Iter 23000, Minibatch Loss= 0.281786, Training Accuracy= 0.89000\n",
      "Iter 24000, Minibatch Loss= 0.437205, Training Accuracy= 0.86000\n",
      "Iter 25000, Minibatch Loss= 0.230427, Training Accuracy= 0.93000\n",
      "Iter 26000, Minibatch Loss= 0.178121, Training Accuracy= 0.95000\n",
      "Iter 27000, Minibatch Loss= 0.224285, Training Accuracy= 0.93000\n",
      "Iter 28000, Minibatch Loss= 0.219034, Training Accuracy= 0.97000\n",
      "Iter 29000, Minibatch Loss= 0.438777, Training Accuracy= 0.87000\n",
      "Iter 30000, Minibatch Loss= 0.421099, Training Accuracy= 0.90000\n",
      "Iter 31000, Minibatch Loss= 0.182418, Training Accuracy= 0.94000\n",
      "Iter 32000, Minibatch Loss= 0.241251, Training Accuracy= 0.92000\n",
      "Iter 33000, Minibatch Loss= 0.115460, Training Accuracy= 0.96000\n",
      "Iter 34000, Minibatch Loss= 0.182184, Training Accuracy= 0.95000\n",
      "Iter 35000, Minibatch Loss= 0.185727, Training Accuracy= 0.92000\n",
      "Iter 36000, Minibatch Loss= 0.121973, Training Accuracy= 0.95000\n",
      "Iter 37000, Minibatch Loss= 0.279088, Training Accuracy= 0.93000\n",
      "Iter 38000, Minibatch Loss= 0.219089, Training Accuracy= 0.92000\n",
      "Iter 39000, Minibatch Loss= 0.149365, Training Accuracy= 0.96000\n",
      "Iter 40000, Minibatch Loss= 0.117735, Training Accuracy= 0.94000\n",
      "Iter 41000, Minibatch Loss= 0.281527, Training Accuracy= 0.90000\n",
      "Iter 42000, Minibatch Loss= 0.209273, Training Accuracy= 0.98000\n",
      "Iter 43000, Minibatch Loss= 0.111538, Training Accuracy= 0.97000\n",
      "Iter 44000, Minibatch Loss= 0.148438, Training Accuracy= 0.93000\n",
      "Iter 45000, Minibatch Loss= 0.273633, Training Accuracy= 0.93000\n",
      "Iter 46000, Minibatch Loss= 0.205813, Training Accuracy= 0.93000\n",
      "Iter 47000, Minibatch Loss= 0.115635, Training Accuracy= 0.96000\n",
      "Iter 48000, Minibatch Loss= 0.073022, Training Accuracy= 0.98000\n",
      "Iter 49000, Minibatch Loss= 0.169398, Training Accuracy= 0.95000\n",
      "Iter 50000, Minibatch Loss= 0.150070, Training Accuracy= 0.95000\n",
      "Iter 51000, Minibatch Loss= 0.078659, Training Accuracy= 0.97000\n",
      "Iter 52000, Minibatch Loss= 0.063444, Training Accuracy= 0.98000\n",
      "Iter 53000, Minibatch Loss= 0.148494, Training Accuracy= 0.95000\n",
      "Iter 54000, Minibatch Loss= 0.062953, Training Accuracy= 0.99000\n",
      "Iter 55000, Minibatch Loss= 0.049891, Training Accuracy= 1.00000\n",
      "Iter 56000, Minibatch Loss= 0.091937, Training Accuracy= 0.97000\n",
      "Iter 57000, Minibatch Loss= 0.257082, Training Accuracy= 0.92000\n",
      "Iter 58000, Minibatch Loss= 0.061131, Training Accuracy= 0.99000\n",
      "Iter 59000, Minibatch Loss= 0.070404, Training Accuracy= 0.98000\n",
      "Iter 60000, Minibatch Loss= 0.128626, Training Accuracy= 0.96000\n",
      "Iter 61000, Minibatch Loss= 0.215072, Training Accuracy= 0.94000\n",
      "Iter 62000, Minibatch Loss= 0.200847, Training Accuracy= 0.94000\n",
      "Iter 63000, Minibatch Loss= 0.082443, Training Accuracy= 0.97000\n",
      "Iter 64000, Minibatch Loss= 0.096185, Training Accuracy= 0.97000\n",
      "Iter 65000, Minibatch Loss= 0.104622, Training Accuracy= 0.96000\n",
      "Iter 66000, Minibatch Loss= 0.082974, Training Accuracy= 0.98000\n",
      "Iter 67000, Minibatch Loss= 0.112266, Training Accuracy= 0.96000\n",
      "Iter 68000, Minibatch Loss= 0.107553, Training Accuracy= 0.98000\n",
      "Iter 69000, Minibatch Loss= 0.037745, Training Accuracy= 1.00000\n",
      "Iter 70000, Minibatch Loss= 0.056981, Training Accuracy= 0.96000\n",
      "Iter 71000, Minibatch Loss= 0.123760, Training Accuracy= 0.96000\n",
      "Iter 72000, Minibatch Loss= 0.050459, Training Accuracy= 0.99000\n",
      "Iter 73000, Minibatch Loss= 0.106084, Training Accuracy= 0.98000\n",
      "Iter 74000, Minibatch Loss= 0.154756, Training Accuracy= 0.96000\n",
      "Iter 75000, Minibatch Loss= 0.111374, Training Accuracy= 0.95000\n",
      "Iter 76000, Minibatch Loss= 0.082636, Training Accuracy= 0.97000\n",
      "Iter 77000, Minibatch Loss= 0.039498, Training Accuracy= 0.99000\n",
      "Iter 78000, Minibatch Loss= 0.121002, Training Accuracy= 0.97000\n",
      "Iter 79000, Minibatch Loss= 0.078736, Training Accuracy= 0.98000\n",
      "Iter 80000, Minibatch Loss= 0.046156, Training Accuracy= 0.97000\n",
      "Iter 81000, Minibatch Loss= 0.072696, Training Accuracy= 0.99000\n",
      "Iter 82000, Minibatch Loss= 0.039800, Training Accuracy= 0.99000\n",
      "Iter 83000, Minibatch Loss= 0.144095, Training Accuracy= 0.97000\n",
      "Iter 84000, Minibatch Loss= 0.066153, Training Accuracy= 0.98000\n",
      "Iter 85000, Minibatch Loss= 0.124993, Training Accuracy= 0.96000\n",
      "Iter 86000, Minibatch Loss= 0.048021, Training Accuracy= 0.99000\n",
      "Iter 87000, Minibatch Loss= 0.034238, Training Accuracy= 1.00000\n",
      "Iter 88000, Minibatch Loss= 0.080688, Training Accuracy= 0.99000\n",
      "Iter 89000, Minibatch Loss= 0.166832, Training Accuracy= 0.95000\n",
      "Iter 90000, Minibatch Loss= 0.047859, Training Accuracy= 0.99000\n",
      "Iter 91000, Minibatch Loss= 0.083528, Training Accuracy= 0.98000\n",
      "Iter 92000, Minibatch Loss= 0.149686, Training Accuracy= 0.95000\n",
      "Iter 93000, Minibatch Loss= 0.103366, Training Accuracy= 0.94000\n",
      "Iter 94000, Minibatch Loss= 0.067120, Training Accuracy= 0.98000\n",
      "Iter 95000, Minibatch Loss= 0.086576, Training Accuracy= 0.98000\n",
      "Iter 96000, Minibatch Loss= 0.038256, Training Accuracy= 1.00000\n",
      "Iter 97000, Minibatch Loss= 0.107564, Training Accuracy= 0.96000\n",
      "Iter 98000, Minibatch Loss= 0.115711, Training Accuracy= 0.95000\n",
      "Iter 99000, Minibatch Loss= 0.051282, Training Accuracy= 0.99000\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.953125)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        # We will read a batch of 100 images [100 x 784] as batch_x\n",
    "        # batch_y is a matrix of [100x10]\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # We consider each row of the image as one sequence\n",
    "        # Reshape data to get 28 seq of 28 elements, so that, batxh_x is [100x28x28]\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    \n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Created by <a href=\"https://br.linkedin.com/in/walter-gomes-de-amorim-junior-624726121\">Walter Gomes de Amorim Junior</a> ,  <a href = \"https://linkedin.com/in/saeedaghabozorgi\"> Saeed Aghabozorgi </a></h4>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
